{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV4q0PYv31bt"
      },
      "source": [
        "Foreword: You need at least 75 GB of RAM available, so if your runtime only gives you e.g. 12.5 system RAM, please reconnect until you're awarded 85 GB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrz1cvFD0WnJ"
      },
      "source": [
        "# Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIz62wWX0cUZ"
      },
      "outputs": [],
      "source": [
        "# unfortunately, we must reinstall deepcell every runtime\n",
        "!pip install deepcell -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGq03lX205mf"
      },
      "outputs": [],
      "source": [
        "from deepcell.applications import Mesmer\n",
        "from deepcell.utils.plot_utils import create_rgb_image\n",
        "from deepcell.utils.plot_utils import make_outline_overlay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RhWdPl_8hpa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import skimage.io as io\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4JK11iL0_lY",
        "outputId": "d1aaa9dc-0b5d-4f64-e391-4d20d7d7ab9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# you should have the ome tiff in your Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GfyRW6N1I51"
      },
      "outputs": [],
      "source": [
        "# replace the file path with your image's, you can find this by right-clicking\n",
        "# on the file in the left panel and copy its path\n",
        "file_path = \"/content/drive/MyDrive/Colab Files/RAM13_003-Brain_131199-2.ome.tif\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpWiCNN63ROu"
      },
      "source": [
        "# Optional: check GPU is accessible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-X8SWZQ3Vq4"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwYR_lEZ3QPZ"
      },
      "outputs": [],
      "source": [
        "# let's check the GPU is on (it should output '/device:GPU:0').\n",
        "# If it isn't check that you have enough compute units left or\n",
        "# click Runtime -> Change runtime type -> select GPU A100 or V100\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALpqmAlq3bnK"
      },
      "source": [
        "# Import and Pre-Process Image and Create RGB of DAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRdD83AC1NXN"
      },
      "outputs": [],
      "source": [
        "image = io.imread(file_path)\n",
        "\n",
        "# we must add an extra axis to fit the parameter requirements\n",
        "# the extra axis is the batch, but we won't care about that\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLOufAGP20GA"
      },
      "source": [
        "# optional: visualize dapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# at least create the DAPI image. The other channels are commented\n",
        "# out for efficiency, but you may display them just as you display\n",
        "# rgb_image1 if you so choose.\n",
        "\n",
        "# rgb_image8 = create_rgb_image(image[:,:,:,7:], channel_colors=['blue'])\n",
        "# rgb_image7 = create_rgb_image(image[:,:,:,6:7], channel_colors=['blue'])\n",
        "# rgb_image6 = create_rgb_image(image[:,:,:,5:6], channel_colors=['blue'])\n",
        "# rgb_image5 = create_rgb_image(image[:,:,:,4:5], channel_colors=['blue'])\n",
        "# rgb_image4 = create_rgb_image(image[:,:,:,3:4], channel_colors=['blue'])\n",
        "# rgb_image3 = create_rgb_image(image[:,:,:,2:3], channel_colors=['blue'])\n",
        "# rgb_image2 = create_rgb_image(image[:,:,:,1:2], channel_colors=['green'])\n",
        "rgb_image1 = create_rgb_image(image[:,:,:,0:1], channel_colors=['blue'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bvINkc21upM"
      },
      "outputs": [],
      "source": [
        "# Let's look at the DAPI\n",
        "# select channel index for displaying\n",
        "idx = 0\n",
        "\n",
        "# plot the data\n",
        "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
        "ax.imshow(rgb_image1[idx, ...])\n",
        "\n",
        "ax.set_title('DAPI')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdk3jc3J3m0V"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVrVFZQ1z8P"
      },
      "outputs": [],
      "source": [
        "# perform nuclear segmentation\n",
        "# this usually takes 14 minutes and will use up 75 GB of RAM\n",
        "\n",
        "app = Mesmer()\n",
        "labeled_image = app.predict(image[:,:,:,0:2], image_mpp=app.model_mpp, compartment='nuclear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTsdm8Vr3pr9"
      },
      "source": [
        "# Optional: Make RGB Overlay and Visualize Overlay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krsl84U62C-l"
      },
      "outputs": [],
      "source": [
        "# make the RGB overlay for optional visualization\n",
        "overlay_data_nuc_big = make_outline_overlay(rgb_data=rgb_image1, predictions=labeled_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzJb3plr2C2T"
      },
      "outputs": [],
      "source": [
        "# optional\n",
        "# display the overlay\n",
        "# select index for displaying\n",
        "idx = 0\n",
        "\n",
        "# plot the data\n",
        "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
        "ax.imshow(overlay_data_nuc_big[idx, ...])\n",
        "ax.set_title('Nuclear Predictions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52wTfIlD3t-M"
      },
      "source": [
        "# Save Mask as Tiff to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4lombXr2OJw"
      },
      "outputs": [],
      "source": [
        "# we don't need the extra batch and channel dimensions for the mask\n",
        "squeezed_array_big = np.squeeze(labeled_image[0,:,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s59Y3JIk2SVC"
      },
      "outputs": [],
      "source": [
        "# optional: if you want to view the mask\n",
        "binary_mask_big = (squeezed_array_big > 0).astype(int)\n",
        "\n",
        "plt.imshow(binary_mask_big, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-54jCtyr2WLb"
      },
      "outputs": [],
      "source": [
        "# optional: if you want to see how many cells detected\n",
        "max_value = np.max(squeezed_array_big)\n",
        "print(max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeBAxC3B2cX_"
      },
      "outputs": [],
      "source": [
        "# save the mask\n",
        "# import skimage.io as io\n",
        "# io.imsave(\"ome_mask_2D.tif\", squeezed_array_big, plugin=\"tifffile\", bigtiff=True)\n",
        "\n",
        "np.save('mask.npy', squeezed_array_big)\n",
        "\n",
        "# upload to Google Drive\n",
        "# !cp ome_mask_2D.tif \"/content/drive/My Drive/Colab Files\"\n",
        "!cp mask.npy \"/content/drive/My Drive/Colab Files\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If You Want to Generate Cytoplasms in Python (Step 2 Method 2). Do the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create pseudo-cytoplasms using constant expansion factor\n",
        "from skimage.segmentation import expand_labels\n",
        "expanded = expand_labels(mask, distance=10)\n",
        "np.save('data/expanded.npy', expanded)\n",
        "# save cytoplasm mask tiff\n",
        "# io.imsave(\"ome_cytoplasms_2D.tif\", expanded, plugin=\"tifffile\", bigtiff=True)\n",
        "\n",
        "# upload to Google Drive\n",
        "# !cp ome_cytoplasms_2D.tif \"/content/drive/My Drive/Colab Files\"\n",
        "!cp expanded.npy \"/content/drive/My Drive/Colab Files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# print(np.array_equal(np.sort(np.unique(mask)), np.sort(np.unique(expanded))))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
